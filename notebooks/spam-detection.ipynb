{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ncount=0\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        count=count+1\n        \nprint(count)\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-26T04:34:32.833008Z","iopub.execute_input":"2021-10-26T04:34:32.833418Z","iopub.status.idle":"2021-10-26T04:35:10.048628Z","shell.execute_reply.started":"2021-10-26T04:34:32.833374Z","shell.execute_reply":"2021-10-26T04:35:10.047492Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nfrom sklearn.datasets import load_files\nfrom sklearn import metrics\nimport time\n\n# Text cleaning and precprcessing\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:40:02.676634Z","iopub.execute_input":"2021-10-26T04:40:02.677097Z","iopub.status.idle":"2021-10-26T04:40:02.686393Z","shell.execute_reply.started":"2021-10-26T04:40:02.677051Z","shell.execute_reply":"2021-10-26T04:40:02.684605Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"X, y = [], []\nemail = load_files(\"../input/enron-spam/enron1\")\nX = np.append(X, email.data)\ny = np.append(y, email.target)   ","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:35:10.625360Z","iopub.execute_input":"2021-10-26T04:35:10.625778Z","iopub.status.idle":"2021-10-26T04:35:29.541389Z","shell.execute_reply.started":"2021-10-26T04:35:10.625730Z","shell.execute_reply":"2021-10-26T04:35:29.540476Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_all = pd.DataFrame(columns=['text', 'target'])\ndf_all['text'] = [x for x in X]\ndf_all['target'] = [t for t in y]","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:35:56.622746Z","iopub.execute_input":"2021-10-26T04:35:56.623079Z","iopub.status.idle":"2021-10-26T04:35:56.795027Z","shell.execute_reply.started":"2021-10-26T04:35:56.623046Z","shell.execute_reply":"2021-10-26T04:35:56.794336Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_X = df_all.drop(['target'], axis=1)\ndf_y = df_all['target']","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:35:58.706012Z","iopub.execute_input":"2021-10-26T04:35:58.706641Z","iopub.status.idle":"2021-10-26T04:35:58.713515Z","shell.execute_reply.started":"2021-10-26T04:35:58.706578Z","shell.execute_reply":"2021-10-26T04:35:58.712678Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"stemmer = PorterStemmer()\nlemmatizer = WordNetLemmatizer()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:36:01.322698Z","iopub.execute_input":"2021-10-26T04:36:01.323727Z","iopub.status.idle":"2021-10-26T04:36:01.327917Z","shell.execute_reply.started":"2021-10-26T04:36:01.323677Z","shell.execute_reply":"2021-10-26T04:36:01.327158Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"corpus = []\nfor i in range(0, len(df_X)):\n    # Remove special symbols\n    review = re.sub(r'\\\\r\\\\n', ' ', str(df_X['text'][i]))\n    # Remove all symbols except letters\n    review = re.sub('[^a-zA-Z]', ' ', review)\n    # Replacing all gaps with spaces \n    review = re.sub(r'\\s+', ' ', review)                    \n    # Remove 'b' in the beginning of each text\n    review = re.sub(r'^b\\s+', '', review)       \n\n    review = review.lower()\n    review = review.split()\n    review = [stemmer.stem(word) for word in review if word not in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:36:06.168459Z","iopub.execute_input":"2021-10-26T04:36:06.169336Z","iopub.status.idle":"2021-10-26T04:38:13.173436Z","shell.execute_reply.started":"2021-10-26T04:36:06.169286Z","shell.execute_reply":"2021-10-26T04:38:13.172452Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n#tf = TfidfVectorizer()\n\n# Creating the Bag of Words model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nX = cv.fit_transform(corpus).toarray()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:38:13.175306Z","iopub.execute_input":"2021-10-26T04:38:13.175685Z","iopub.status.idle":"2021-10-26T04:38:14.410991Z","shell.execute_reply.started":"2021-10-26T04:38:13.175646Z","shell.execute_reply":"2021-10-26T04:38:14.409829Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,  random_state=9, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:38:21.126771Z","iopub.execute_input":"2021-10-26T04:38:21.127133Z","iopub.status.idle":"2021-10-26T04:38:21.780683Z","shell.execute_reply.started":"2021-10-26T04:38:21.127100Z","shell.execute_reply":"2021-10-26T04:38:21.779654Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix\n\n\nmodel = MultinomialNB().fit(X_train, y_train)\npred = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, pred)\n# precision = precision_score(y_test, pred)\n# recall = recall_score(y_test, pred)\n# conf_m = confusion_matrix(y_test, pred)\n\nprint(\"MultinomialNB:\",accuracy)\n# print(f\"precision: %.3f\" %precision)\n# print(f\"recall: %.3f\" %recall)\n# print(f\"confusion matrix: \")\n# print(conf_m)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T15:18:00.207644Z","iopub.execute_input":"2021-10-25T15:18:00.208033Z","iopub.status.idle":"2021-10-25T15:18:01.453966Z","shell.execute_reply.started":"2021-10-25T15:18:00.207983Z","shell.execute_reply":"2021-10-25T15:18:01.453053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nmodel2 = KNeighborsClassifier(n_neighbors=4)\nmodel2.fit(X_train, y_train)\ny_pred = model2.predict(X_test)\nprint(\"KNN Accuracy:\",metrics.accuracy_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-25T15:18:03.807001Z","iopub.execute_input":"2021-10-25T15:18:03.807278Z","iopub.status.idle":"2021-10-25T15:23:15.607799Z","shell.execute_reply.started":"2021-10-25T15:18:03.807248Z","shell.execute_reply":"2021-10-25T15:23:15.606506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3: 85.70048309178744%\n4: 85.99033816425121%\n5: 84%\n7: 82%","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nmodel3=LogisticRegression()\nmodel3.fit(X_train, y_train)\npred = model3.predict(X_test)\nprint(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-25T15:16:17.986244Z","iopub.execute_input":"2021-10-25T15:16:17.986559Z","iopub.status.idle":"2021-10-25T15:16:24.463047Z","shell.execute_reply.started":"2021-10-25T15:16:17.986529Z","shell.execute_reply":"2021-10-25T15:16:24.461969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logistic regression:86.28019323671497%","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\ny_pred=clf.predict(X_test)\nprint(\"RandomForest Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-26T04:38:30.173238Z","iopub.execute_input":"2021-10-26T04:38:30.174637Z","iopub.status.idle":"2021-10-26T04:39:02.657261Z","shell.execute_reply.started":"2021-10-26T04:38:30.174566Z","shell.execute_reply":"2021-10-26T04:39:02.655946Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn import metrics\nclf2 = SVC(kernel='linear')\nclf2.fit(X_train,y_train)\ny_pred = clf2.predict(X_test)\nprint(\"SVM Accuracy:\",metrics.accuracy_score(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-26T03:19:40.422447Z","iopub.execute_input":"2021-10-26T03:19:40.422782Z","iopub.status.idle":"2021-10-26T03:23:15.611525Z","shell.execute_reply.started":"2021-10-26T03:19:40.422746Z","shell.execute_reply":"2021-10-26T03:23:15.610562Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# from sklearn.externals import joblib\nimport pickle\nfilename = 'finalized_SVMmodel.sav'\npickle.dump(clf, open(filename, 'wb'))\n \n# # Save the model as a pickle in a file\n# joblib.dump(clf2, 'filename.pkl')\n \n# # Load the model from the file\n# knn_from_joblib = joblib.load('filename.pkl')\n \n# # Use the loaded model to make predictions\n# knn_from_joblib.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\n  \n# making predictions on the testing set\ny_pred = gnb.predict(X_test)\n  \n# comparing actual response values (y_test) with predicted response values (y_pred)\nprint(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random Forest: 98.16425120772947%\nSVM: 98.55072463768116%\nGaussian Naive Bayes model accuracy: 93.33333333333333%\nLogistic regression:86.28019323671497%\nKNN(n=3):85.70048309178744%\nKNN(n=4): 85.99033816425121%\nMultinomialNB: 97.77777777777777%","metadata":{}},{"cell_type":"code","source":"# plt.scatter(X_test,pred, s=10)\n# plt.xlabel('x')\n# plt.ylabel('y')\n\n\n# plt.plot(X_test, y_predicted, color='r')\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}